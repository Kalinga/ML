{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://github.com/adventuresinML/adventures-in-ml-code/blob/master/keras_lstm.py\n",
    "    \n",
    "from math import sqrt\n",
    "from numpy import concatenate\n",
    "from matplotlib import pyplot\n",
    "\n",
    "from pandas import read_csv\n",
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    "import numpy as np\n",
    "\n",
    "# for scaling and inverse_transform\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "from keras.models import load_model\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, TerminateOnNaN, CSVLogger\n",
    "\n",
    "import pickle\n",
    "from os import listdir\n",
    "\n",
    "# convert series to supervised learning\n",
    "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "\tprint(type(data))\n",
    "\tn_vars = 1 if type(data) is list else data.shape[1]\n",
    "\tdf = DataFrame(data)\n",
    "\tcols, names = list(), list()\n",
    "\n",
    "\t# input sequence (t-n, ... t-1)\n",
    "\tfor i in range(n_in, 0, -1): # range([start,] stop [, step])\n",
    "        # DataFrame.shift(periods=1, freq=None, axis=0), returns DataFrame\n",
    "\t\tcols.append(df.shift(i)) \n",
    "\t\tnames += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "\t# forecast sequence (t, t+1, ... t+n)\n",
    "\t# We are only interested in final bb after certain frames, e.g. 31st, 61st etc\n",
    "\tfor i in range(n_out - 1 , n_out): #next element (n_out, n_out + 1) introduce error!!\n",
    "\t\tcols.append(df.shift(-i))\n",
    "\t\tif i == 0:\n",
    "\t\t\tnames += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "\t\telse:\n",
    "\t\t\tnames += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "\t# put it all together\n",
    "    #  concatenating along the columns (axis=1), a DataFrame is returned.\n",
    "\tagg = concat(cols, axis=1)\n",
    "\tagg.columns = names\n",
    "\t# drop rows with NaN values\n",
    "\tif dropnan:\n",
    "\t\tagg.dropna(inplace=True)\n",
    "\treturn agg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(84371, 4)\n",
      "[1900.  953. 1919. 1079.]\n",
      "[0. 0. 0. 0.]\n",
      "<class 'numpy.ndarray'>\n",
      "(84312, 124)\n",
      "(64372, 120) 64372 (64372, 4)\n",
      "(64372, 30, 4) (64372, 4) (19940, 30, 4) (19940, 4)\n"
     ]
    }
   ],
   "source": [
    "# load dataset\n",
    "dataset = read_csv('bb-cross-train.csv', header=0)\n",
    "values = dataset.values\n",
    "print(values.shape)\n",
    "\n",
    "# ensure all data is float\n",
    "values = values.astype('float32')\n",
    "\n",
    "# normalize features\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled = scaler.fit_transform(values)\n",
    "print(scaler.data_max_)\n",
    "print(scaler.data_min_)\n",
    "\n",
    "pickle.dump(scaler, open(\"min-max-scaler.pkl\", 'wb'))\n",
    "\n",
    "# specify the number of lag hours\n",
    "n_seq = 30\n",
    "n_seq_future = 30\n",
    "n_features = 4\n",
    "# frame as supervised learning\n",
    "reframed = series_to_supervised(scaled, n_seq, n_seq_future)\n",
    "print(reframed.shape)\n",
    "\n",
    "# split into train and test sets\n",
    "values = reframed.values\n",
    "n_train_num = 84372 - 20000\n",
    "train = values[:n_train_num, :]\n",
    "val = values[n_train_num:, :]\n",
    "\n",
    "# split into input and outputs\n",
    "n_obs = n_seq * n_features\n",
    "train_X, train_y = train[:, :n_obs], train[:, n_obs:n_obs+n_features]\n",
    "val_X, val_y = val[:, :n_obs], val[:, n_obs:n_obs+n_features]\n",
    "print(train_X.shape, len(train_X), train_y.shape)\n",
    "\n",
    "# reshape input to be 3D [samples, timesteps, features]\n",
    "train_X = train_X.reshape((train_X.shape[0], n_seq, n_features))\n",
    "val_X = val_X.reshape((val_X.shape[0], n_seq, n_features))\n",
    "print(train_X.shape, train_y.shape, val_X.shape, val_y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_csv = [\"train/%s\" %f for f in listdir(\"./train\")]\n",
    "#print(train_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "del reframed\n",
    "reframed = np.zeros( (1,124) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(reframed[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(284, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(226, 124)\n",
      "(84, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(251, 124)\n",
      "(273, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(465, 124)\n",
      "(119, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(525, 124)\n",
      "(170, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(636, 124)\n",
      "(113, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(690, 124)\n",
      "(239, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(870, 124)\n",
      "(149, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(960, 124)\n",
      "(330, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(1231, 124)\n",
      "(144, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(1316, 124)\n",
      "(149, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(1406, 124)\n",
      "(289, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(1636, 124)\n",
      "(293, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(1870, 124)\n",
      "(175, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(1986, 124)\n",
      "(239, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(2166, 124)\n",
      "(179, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(2286, 124)\n",
      "(299, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(2526, 124)\n",
      "(239, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(2706, 124)\n",
      "(149, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(2796, 124)\n",
      "(107, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(2844, 124)\n",
      "(209, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(2994, 124)\n",
      "(237, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(3172, 124)\n",
      "(209, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(3322, 124)\n",
      "(201, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(3464, 124)\n",
      "(239, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(3644, 124)\n",
      "(209, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(3794, 124)\n",
      "(414, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(4149, 124)\n",
      "(209, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(4299, 124)\n",
      "(200, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(4440, 124)\n",
      "(358, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(4739, 124)\n",
      "(179, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(4859, 124)\n",
      "(130, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(4930, 124)\n",
      "(89, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(4960, 124)\n",
      "(216, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(5117, 124)\n",
      "(269, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(5327, 124)\n",
      "(167, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(5435, 124)\n",
      "(321, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(5697, 124)\n",
      "(289, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(5927, 124)\n",
      "(299, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(6167, 124)\n",
      "(232, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(6340, 124)\n",
      "(214, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(6495, 124)\n",
      "(256, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(6692, 124)\n",
      "(149, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(6782, 124)\n",
      "(108, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(6831, 124)\n",
      "(84, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(6856, 124)\n",
      "(89, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(6886, 124)\n",
      "(250, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(7077, 124)\n",
      "(185, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(7203, 124)\n",
      "(239, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(7383, 124)\n",
      "(74, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(7398, 124)\n",
      "(239, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(7578, 124)\n",
      "(239, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(7758, 124)\n",
      "(269, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(7968, 124)\n",
      "(268, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(8177, 124)\n",
      "(269, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(8387, 124)\n",
      "(179, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(8507, 124)\n",
      "(160, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(8608, 124)\n",
      "(253, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(8802, 124)\n",
      "(197, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(8940, 124)\n",
      "(149, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(9030, 124)\n",
      "(339, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(9310, 124)\n",
      "(45, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(9310, 124)\n",
      "(122, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(9373, 124)\n",
      "(296, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(9610, 124)\n",
      "(180, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(9731, 124)\n",
      "(269, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(9941, 124)\n",
      "(327, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(10209, 124)\n",
      "(259, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(10409, 124)\n",
      "(167, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(10517, 124)\n",
      "(239, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(10697, 124)\n",
      "(262, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(10900, 124)\n",
      "(239, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(11080, 124)\n",
      "(119, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(11140, 124)\n",
      "(292, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(11373, 124)\n",
      "(224, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(11538, 124)\n",
      "(39, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(11538, 124)\n",
      "(119, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(11598, 124)\n",
      "(135, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(11674, 124)\n",
      "(269, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(11884, 124)\n",
      "(174, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(11999, 124)\n",
      "(209, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(12149, 124)\n",
      "(263, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(12353, 124)\n",
      "(31, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(12353, 124)\n",
      "(179, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(12473, 124)\n",
      "(157, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(12571, 124)\n",
      "(179, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(12691, 124)\n",
      "(286, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(12918, 124)\n",
      "(209, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(13068, 124)\n",
      "(168, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(13177, 124)\n",
      "(121, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(13239, 124)\n",
      "(199, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(13379, 124)\n",
      "(228, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(13548, 124)\n",
      "(380, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(13869, 124)\n",
      "(174, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(13984, 124)\n",
      "(280, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(14205, 124)\n",
      "(350, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(14496, 124)\n",
      "(329, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(14766, 124)\n",
      "(277, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(14984, 124)\n",
      "(149, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(15074, 124)\n",
      "(179, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(15194, 124)\n",
      "(224, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(15359, 124)\n",
      "(149, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(15449, 124)\n",
      "(264, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(15654, 124)\n",
      "(176, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(15771, 124)\n",
      "(222, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(15934, 124)\n",
      "(239, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(16114, 124)\n",
      "(149, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(16204, 124)\n",
      "(209, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(16354, 124)\n",
      "(204, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(16499, 124)\n",
      "(150, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(16590, 124)\n",
      "(281, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(16812, 124)\n",
      "(239, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(16992, 124)\n",
      "(328, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(17261, 124)\n",
      "(269, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(17471, 124)\n",
      "(149, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(17561, 124)\n",
      "(161, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(17663, 124)\n",
      "(169, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(17773, 124)\n",
      "(232, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(17946, 124)\n",
      "(288, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(18175, 124)\n",
      "(104, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(18220, 124)\n",
      "(259, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(18420, 124)\n",
      "(299, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(18660, 124)\n",
      "(231, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(18832, 124)\n",
      "(39, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(18832, 124)\n",
      "(224, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(18997, 124)\n",
      "(119, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(19057, 124)\n",
      "(151, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(19149, 124)\n",
      "(119, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(19209, 124)\n",
      "(312, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(19462, 124)\n",
      "(269, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(19672, 124)\n",
      "(202, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(19815, 124)\n",
      "(119, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(19875, 124)\n",
      "(272, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(20088, 124)\n",
      "(232, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(20261, 124)\n",
      "(586, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(20788, 124)\n",
      "(175, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(20904, 124)\n",
      "(204, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(21049, 124)\n",
      "(151, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(21141, 124)\n",
      "(260, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(21342, 124)\n",
      "(149, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(21432, 124)\n",
      "(431, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(21804, 124)\n",
      "(155, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(21900, 124)\n",
      "(149, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(21990, 124)\n",
      "(111, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(22042, 124)\n",
      "(329, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(22312, 124)\n",
      "(237, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(22490, 124)\n",
      "(119, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(22550, 124)\n",
      "(359, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(22850, 124)\n",
      "(469, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(23260, 124)\n",
      "(244, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(23445, 124)\n",
      "(150, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(23536, 124)\n",
      "(90, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(23567, 124)\n",
      "(171, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(23679, 124)\n",
      "(239, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(23859, 124)\n",
      "(108, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(23908, 124)\n",
      "(166, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(24015, 124)\n",
      "(134, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(24090, 124)\n",
      "(137, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(24168, 124)\n",
      "(230, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(24339, 124)\n",
      "(230, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(24510, 124)\n",
      "(319, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(24770, 124)\n",
      "(252, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(24963, 124)\n",
      "(244, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(25148, 124)\n",
      "(296, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(25385, 124)\n",
      "(276, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(25602, 124)\n",
      "(218, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(25761, 124)\n",
      "(49, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(25761, 124)\n",
      "(208, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(25910, 124)\n",
      "(311, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(26162, 124)\n",
      "(188, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(26291, 124)\n",
      "(203, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(26435, 124)\n",
      "(281, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(26657, 124)\n",
      "(115, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(26713, 124)\n",
      "(201, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(26855, 124)\n",
      "(71, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(26867, 124)\n",
      "(233, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(27041, 124)\n",
      "(61, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(27043, 124)\n",
      "(239, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(27223, 124)\n",
      "(109, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(27273, 124)\n",
      "(203, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(27417, 124)\n",
      "(329, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(27687, 124)\n",
      "(172, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(27800, 124)\n",
      "(149, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(27890, 124)\n",
      "(160, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(27991, 124)\n",
      "(174, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(28106, 124)\n",
      "(149, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(28196, 124)\n",
      "(119, 4)\n",
      "<class 'numpy.ndarray'>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28256, 124)\n",
      "(149, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(28346, 124)\n",
      "(149, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(28436, 124)\n",
      "(239, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(28616, 124)\n",
      "(149, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(28706, 124)\n",
      "(281, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(28928, 124)\n",
      "(206, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(29075, 124)\n",
      "(209, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(29225, 124)\n",
      "(179, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(29345, 124)\n",
      "(269, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(29555, 124)\n",
      "(231, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(29727, 124)\n",
      "(182, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(29850, 124)\n",
      "(118, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(29909, 124)\n",
      "(149, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(29999, 124)\n",
      "(242, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(30182, 124)\n",
      "(495, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(30618, 124)\n",
      "(239, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(30798, 124)\n",
      "(169, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(30908, 124)\n",
      "(149, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(30998, 124)\n",
      "(296, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(31235, 124)\n",
      "(334, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(31510, 124)\n",
      "(329, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(31780, 124)\n",
      "(241, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(31962, 124)\n",
      "(293, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(32196, 124)\n",
      "(269, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(32406, 124)\n",
      "(177, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(32524, 124)\n",
      "(142, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(32607, 124)\n",
      "(222, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(32770, 124)\n",
      "(201, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(32912, 124)\n",
      "(234, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(33087, 124)\n",
      "(239, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(33267, 124)\n",
      "(255, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(33463, 124)\n",
      "(194, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(33598, 124)\n",
      "(114, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(33653, 124)\n",
      "(323, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(33917, 124)\n",
      "(225, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(34083, 124)\n",
      "(389, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(34413, 124)\n",
      "(149, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(34503, 124)\n",
      "(232, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(34676, 124)\n",
      "(116, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(34733, 124)\n",
      "(76, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(34750, 124)\n",
      "(129, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(34820, 124)\n",
      "(179, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(34940, 124)\n",
      "(260, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(35141, 124)\n",
      "(84, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(35166, 124)\n",
      "(290, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(35397, 124)\n",
      "(149, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(35487, 124)\n",
      "(119, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(35547, 124)\n",
      "(134, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(35622, 124)\n",
      "(209, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(35772, 124)\n",
      "(72, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(35785, 124)\n",
      "(215, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(35941, 124)\n",
      "(204, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(36086, 124)\n",
      "(115, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(36142, 124)\n",
      "(241, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(36324, 124)\n",
      "(197, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(36462, 124)\n",
      "(172, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(36575, 124)\n",
      "(119, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(36635, 124)\n",
      "(117, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(36693, 124)\n",
      "(209, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(36843, 124)\n",
      "(188, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(36972, 124)\n",
      "(239, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(37152, 124)\n",
      "(160, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(37253, 124)\n",
      "(209, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(37403, 124)\n",
      "(179, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(37523, 124)\n",
      "(199, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(37663, 124)\n",
      "(119, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(37723, 124)\n",
      "(89, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(37753, 124)\n",
      "(179, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(37873, 124)\n",
      "(210, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(38024, 124)\n",
      "(243, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(38208, 124)\n",
      "(312, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(38461, 124)\n",
      "(179, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(38581, 124)\n",
      "(105, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(38627, 124)\n",
      "(209, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(38777, 124)\n",
      "(125, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(38843, 124)\n",
      "(141, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(38925, 124)\n",
      "(266, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(39132, 124)\n",
      "(227, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(39300, 124)\n",
      "(111, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(39352, 124)\n",
      "(103, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(39396, 124)\n",
      "(149, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(39486, 124)\n",
      "(149, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(39576, 124)\n",
      "(359, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(39876, 124)\n",
      "(109, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(39926, 124)\n",
      "(232, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(40099, 124)\n",
      "(209, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(40249, 124)\n",
      "(149, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(40339, 124)\n",
      "(164, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(40444, 124)\n",
      "(89, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(40474, 124)\n",
      "(149, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(40564, 124)\n",
      "(137, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(40642, 124)\n",
      "(170, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(40753, 124)\n",
      "(309, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(41003, 124)\n",
      "(239, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(41183, 124)\n",
      "(259, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(41383, 124)\n",
      "(231, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(41555, 124)\n",
      "(119, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(41615, 124)\n",
      "(209, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(41765, 124)\n",
      "(290, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(41996, 124)\n",
      "(369, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(42306, 124)\n",
      "(193, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(42440, 124)\n",
      "(230, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(42611, 124)\n",
      "(149, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(42701, 124)\n",
      "(247, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(42889, 124)\n",
      "(259, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(43089, 124)\n",
      "(109, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(43139, 124)\n",
      "(218, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(43298, 124)\n",
      "(239, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(43478, 124)\n",
      "(149, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(43568, 124)\n",
      "(579, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(44088, 124)\n",
      "(287, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(44316, 124)\n",
      "(153, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(44410, 124)\n",
      "(143, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(44494, 124)\n",
      "(151, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(44586, 124)\n",
      "(119, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(44646, 124)\n",
      "(368, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(44955, 124)\n",
      "(149, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(45045, 124)\n",
      "(133, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(45119, 124)\n",
      "(169, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(45229, 124)\n",
      "(149, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(45319, 124)\n",
      "(232, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(45492, 124)\n",
      "(253, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(45686, 124)\n",
      "(186, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(45813, 124)\n",
      "(315, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(46069, 124)\n",
      "(179, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(46189, 124)\n",
      "(252, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(46382, 124)\n",
      "(179, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(46502, 124)\n",
      "(149, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(46592, 124)\n",
      "(307, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(46840, 124)\n",
      "(209, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(46990, 124)\n",
      "(229, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(47160, 124)\n",
      "(299, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(47400, 124)\n",
      "(190, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(47531, 124)\n",
      "(87, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(47559, 124)\n",
      "(185, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(47685, 124)\n",
      "(209, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(47835, 124)\n",
      "(179, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(47955, 124)\n",
      "(119, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(48015, 124)\n",
      "(237, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(48193, 124)\n",
      "(477, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(48611, 124)\n",
      "(189, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(48741, 124)\n",
      "(250, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(48932, 124)\n",
      "(282, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(49155, 124)\n",
      "(198, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(49294, 124)\n",
      "(290, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(49525, 124)\n",
      "(123, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(49589, 124)\n",
      "(143, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(49673, 124)\n",
      "(146, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(49760, 124)\n",
      "(186, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(49887, 124)\n",
      "(158, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(49986, 124)\n",
      "(118, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(50045, 124)\n",
      "(239, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(50225, 124)\n",
      "(281, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(50447, 124)\n",
      "(43, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(50447, 124)\n",
      "(358, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(50746, 124)\n",
      "(239, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(50926, 124)\n",
      "(209, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(51076, 124)\n",
      "(239, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(51256, 124)\n",
      "(164, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(51361, 124)\n",
      "(149, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(51451, 124)\n",
      "(203, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(51595, 124)\n",
      "(209, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(51745, 124)\n",
      "(332, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(52018, 124)\n",
      "(335, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(52294, 124)\n",
      "(113, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(52348, 124)\n",
      "(77, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(52366, 124)\n",
      "(149, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(52456, 124)\n",
      "(272, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(52669, 124)\n",
      "(218, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(52828, 124)\n",
      "(180, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(52949, 124)\n",
      "(154, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(53044, 124)\n",
      "(144, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(53129, 124)\n",
      "(149, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(53219, 124)\n",
      "(239, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(53399, 124)\n",
      "(149, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(53489, 124)\n",
      "(119, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(53549, 124)\n",
      "(146, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(53636, 124)\n",
      "(239, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(53816, 124)\n",
      "(149, 4)\n",
      "<class 'numpy.ndarray'>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(53906, 124)\n",
      "(118, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(53965, 124)\n",
      "(150, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(54056, 124)\n",
      "(234, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(54231, 124)\n",
      "(158, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(54330, 124)\n",
      "(57, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(54330, 124)\n",
      "(145, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(54416, 124)\n",
      "(188, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(54545, 124)\n",
      "(122, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(54608, 124)\n",
      "(206, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(54755, 124)\n",
      "(149, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(54845, 124)\n",
      "(346, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(55132, 124)\n",
      "(239, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(55312, 124)\n",
      "(179, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(55432, 124)\n",
      "(138, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(55511, 124)\n",
      "(304, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(55756, 124)\n",
      "(347, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(56044, 124)\n",
      "(152, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(56137, 124)\n",
      "(208, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(56286, 124)\n",
      "(209, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(56436, 124)\n",
      "(270, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(56647, 124)\n",
      "(299, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(56887, 124)\n",
      "(137, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(56965, 124)\n",
      "(204, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(57110, 124)\n",
      "(183, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(57234, 124)\n",
      "(172, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(57347, 124)\n",
      "(149, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(57437, 124)\n",
      "(152, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(57530, 124)\n",
      "(216, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(57687, 124)\n",
      "(149, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(57777, 124)\n",
      "(292, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(58010, 124)\n",
      "(289, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(58240, 124)\n",
      "(193, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(58374, 124)\n",
      "(226, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(58541, 124)\n",
      "(271, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(58753, 124)\n",
      "(209, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(58903, 124)\n",
      "(130, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(58974, 124)\n",
      "(208, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(59123, 124)\n",
      "(105, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(59169, 124)\n",
      "(128, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(59238, 124)\n",
      "(149, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(59328, 124)\n",
      "(125, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(59394, 124)\n",
      "(260, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(59595, 124)\n",
      "(59594, 124)\n",
      "(59594, 124)\n",
      "39594\n",
      "(39594, 120) 39594 (39594, 4)\n",
      "(39594, 30, 4) (39594, 4) (20000, 30, 4) (20000, 4)\n"
     ]
    }
   ],
   "source": [
    "# specify the number of lag hours\n",
    "n_seq = 30\n",
    "n_seq_future = 30\n",
    "n_features = 4\n",
    "np.array(reframed, dtype='float32')\n",
    "# load dataset\n",
    "#train_csv = [\"train/0_184_1327b.csv\", \"train/0_221_1667b.csv\"]\n",
    "for f in train_csv:\n",
    "    dataset = read_csv(f, header=0)\n",
    "    values = dataset.values\n",
    "    print(values.shape)\n",
    "\n",
    "    # ensure all data is float\n",
    "    values = values.astype('float32')\n",
    "\n",
    "    # normalize features\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    scaled = scaler.fit_transform(values)\n",
    "    #print(scaler.data_max_)\n",
    "    #print(scaler.data_min_)\n",
    "\n",
    "    # frame as supervised learning\n",
    "    reframed = np.append(reframed, series_to_supervised(scaled, n_seq, n_seq_future), axis = 0)\n",
    "    print(reframed.shape)\n",
    "reframed = np.delete(reframed, 0, axis = 0)\n",
    "print(reframed.shape)\n",
    "# split into train and test sets\n",
    "values = reframed\n",
    "print(values.shape)\n",
    "n_train_num = reframed.shape[0] - 20000\n",
    "print(n_train_num)\n",
    "train = values[:n_train_num, :]\n",
    "val = values[n_train_num:, :]\n",
    "\n",
    "# split into input and outputs\n",
    "n_obs = n_seq * n_features\n",
    "train_X, train_y = train[:, :n_obs], train[:, n_obs:n_obs+n_features]\n",
    "val_X, val_y = val[:, :n_obs], val[:, n_obs:n_obs+n_features]\n",
    "print(train_X.shape, len(train_X), train_y.shape)\n",
    "\n",
    "# reshape input to be 3D [samples, timesteps, features]\n",
    "train_X = train_X.reshape((train_X.shape[0], n_seq, n_features))\n",
    "val_X = val_X.reshape((val_X.shape[0], n_seq, n_features))\n",
    "print(train_X.shape, train_y.shape, val_X.shape, val_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59594"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reframed.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(59594, 124)\n"
     ]
    }
   ],
   "source": [
    "print(reframed.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.9369108 , 0.01136351, 0.923686  , 0.        ], dtype=float32)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39594, 30, 4)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 30, 4)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model callbacks.\n",
    "\n",
    "# TODO: Set the filepath under which you want to save the weights.\n",
    "model_checkpoint = ModelCheckpoint(filepath='30f_future_epoch-{epoch:02d}_loss-{loss:.4f}_val_loss-{val_loss:.4f}.h5',\n",
    "                                   monitor='val_loss',\n",
    "                                   verbose=1,\n",
    "                                   save_best_only=True,\n",
    "                                   save_weights_only=False,\n",
    "                                   mode='auto',\n",
    "                                   period=1)\n",
    "\n",
    "csv_logger = CSVLogger(filename='bb_lstm_training_log.csv',\n",
    "                       separator=',',\n",
    "                       append=True)\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss',\n",
    "                               min_delta=0.0,\n",
    "                               patience=10,\n",
    "                               verbose=1)\n",
    "\n",
    "#reduce_learning_rate = ReduceLROnPlateau(monitor='val_loss',\n",
    "#                                         factor=0.2,\n",
    "#                                         patience=8,\n",
    "#                                         verbose=1,\n",
    "#                                         epsilon=0.001,\n",
    "#                                         cooldown=0,\n",
    "#                                         min_lr=0.00001)\n",
    "\n",
    "callbacks = [model_checkpoint,\n",
    "             csv_logger,\n",
    "             early_stopping\n",
    "             #reduce_learning_rate]\n",
    "            ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 39594 samples, validate on 20000 samples\n",
      "Epoch 1/200\n",
      " - 33s - loss: 0.1775 - val_loss: 0.1463\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.14628, saving model to 30f_future_epoch-01_loss-0.1775_val_loss-0.1463.h5\n",
      "Epoch 2/200\n",
      " - 31s - loss: 0.1504 - val_loss: 0.1394\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.14628 to 0.13943, saving model to 30f_future_epoch-02_loss-0.1504_val_loss-0.1394.h5\n",
      "Epoch 3/200\n",
      " - 31s - loss: 0.1414 - val_loss: 0.1249\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.13943 to 0.12492, saving model to 30f_future_epoch-03_loss-0.1414_val_loss-0.1249.h5\n",
      "Epoch 4/200\n",
      " - 31s - loss: 0.1273 - val_loss: 0.1136\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.12492 to 0.11358, saving model to 30f_future_epoch-04_loss-0.1273_val_loss-0.1136.h5\n",
      "Epoch 5/200\n",
      " - 31s - loss: 0.1193 - val_loss: 0.1079\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.11358 to 0.10788, saving model to 30f_future_epoch-05_loss-0.1193_val_loss-0.1079.h5\n",
      "Epoch 6/200\n",
      " - 31s - loss: 0.1137 - val_loss: 0.1092\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.10788\n",
      "Epoch 7/200\n",
      " - 31s - loss: 0.1112 - val_loss: 0.1048\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.10788 to 0.10481, saving model to 30f_future_epoch-07_loss-0.1112_val_loss-0.1048.h5\n",
      "Epoch 8/200\n",
      " - 31s - loss: 0.1077 - val_loss: 0.1092\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.10481\n",
      "Epoch 9/200\n",
      " - 31s - loss: 0.1063 - val_loss: 0.0993\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.10481 to 0.09926, saving model to 30f_future_epoch-09_loss-0.1063_val_loss-0.0993.h5\n",
      "Epoch 10/200\n",
      " - 31s - loss: 0.1038 - val_loss: 0.0984\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.09926 to 0.09841, saving model to 30f_future_epoch-10_loss-0.1038_val_loss-0.0984.h5\n",
      "Epoch 11/200\n",
      " - 31s - loss: 0.1028 - val_loss: 0.0969\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.09841 to 0.09688, saving model to 30f_future_epoch-11_loss-0.1028_val_loss-0.0969.h5\n",
      "Epoch 12/200\n",
      " - 31s - loss: 0.1017 - val_loss: 0.1036\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.09688\n",
      "Epoch 13/200\n",
      " - 31s - loss: 0.1023 - val_loss: 0.1058\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.09688\n",
      "Epoch 14/200\n",
      " - 31s - loss: 0.0996 - val_loss: 0.1036\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.09688\n",
      "Epoch 15/200\n",
      " - 31s - loss: 0.0991 - val_loss: 0.0966\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.09688 to 0.09661, saving model to 30f_future_epoch-15_loss-0.0991_val_loss-0.0966.h5\n",
      "Epoch 16/200\n",
      " - 31s - loss: 0.0980 - val_loss: 0.0984\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.09661\n",
      "Epoch 17/200\n",
      " - 31s - loss: 0.0973 - val_loss: 0.1064\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.09661\n",
      "Epoch 18/200\n",
      " - 31s - loss: 0.0974 - val_loss: 0.0957\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.09661 to 0.09570, saving model to 30f_future_epoch-18_loss-0.0974_val_loss-0.0957.h5\n",
      "Epoch 19/200\n",
      " - 31s - loss: 0.0966 - val_loss: 0.0966\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.09570\n",
      "Epoch 20/200\n",
      " - 31s - loss: 0.0957 - val_loss: 0.1024\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.09570\n",
      "Epoch 21/200\n",
      " - 31s - loss: 0.0959 - val_loss: 0.0949\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.09570 to 0.09487, saving model to 30f_future_epoch-21_loss-0.0959_val_loss-0.0949.h5\n",
      "Epoch 22/200\n",
      " - 31s - loss: 0.0950 - val_loss: 0.1035\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.09487\n",
      "Epoch 23/200\n",
      " - 32s - loss: 0.0961 - val_loss: 0.1030\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.09487\n",
      "Epoch 24/200\n",
      " - 31s - loss: 0.0957 - val_loss: 0.1007\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.09487\n",
      "Epoch 25/200\n",
      " - 31s - loss: 0.0949 - val_loss: 0.1022\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.09487\n",
      "Epoch 26/200\n",
      " - 31s - loss: 0.0937 - val_loss: 0.0946\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.09487 to 0.09463, saving model to 30f_future_epoch-26_loss-0.0937_val_loss-0.0946.h5\n",
      "Epoch 27/200\n"
     ]
    }
   ],
   "source": [
    " # design network\n",
    "K.clear_session()  # Clear previous models from memory.    \n",
    "model = Sequential()\n",
    "model.add(LSTM(50, input_shape=(train_X.shape[1], train_X.shape[2])))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(4))\n",
    "model.compile(loss='mae', optimizer='adam')\n",
    "#A loss function or objective function, or optimization score function\n",
    "#mean_absolute_error\n",
    "\n",
    "epochs = 200\n",
    "# fit network\n",
    "history = model.fit(train_X, train_y, \n",
    "                    epochs=epochs, \n",
    "                    batch_size=72, \n",
    "                    validation_data=(val_X, val_y), \n",
    "                    verbose=2,\n",
    "                    callbacks=callbacks,\n",
    "                    shuffle=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot history\n",
    "pyplot.plot(history.history['loss'], label='train')\n",
    "pyplot.plot(history.history['val_loss'], label='test')\n",
    "pyplot.legend()\n",
    "pyplot.savefig(\"30f_future.png\")\n",
    "pyplot.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model\n",
    "model.save(\"30f_future_epoch-lstm-model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "204\n",
      "[1900.  953. 1919. 1079.]\n",
      "[0. 0. 0. 0.]\n",
      "<class 'numpy.ndarray'>\n",
      "(173, 124)\n",
      "(173, 120) 173 (173, 4)\n",
      "(173, 30, 4) (173, 4)\n"
     ]
    }
   ],
   "source": [
    "# load test dataset\n",
    "values = read_csv('bb-cross-test1.csv', header=0).values\n",
    "print(len(values))\n",
    "# ensure all data is float\n",
    "values = values.astype('float32')\n",
    "\n",
    "# normalize features\n",
    "\n",
    "scaled = scaler.transform(values)\n",
    "print(scaler.data_max_)\n",
    "print(scaler.data_min_)\n",
    "\n",
    "# specify the number of lag hours\n",
    "#n_seq = 15\n",
    "#n_features = 4\n",
    "\n",
    "# frame as supervised learning\n",
    "reframed = series_to_supervised(scaled, n_seq, 1)\n",
    "print(reframed.shape)\n",
    "values = reframed.values\n",
    "\n",
    "# split into input and outputs\n",
    "n_obs = n_seq * n_features\n",
    "test_X, test_y = values[:, :n_obs], values[:, n_obs:n_obs+n_features]\n",
    "print(test_X.shape, len(test_X), test_y.shape)\n",
    "\n",
    "# reshape input to be 3D [samples, timesteps, features]\n",
    "test_X = test_X.reshape((test_X.shape[0], n_seq, n_features))\n",
    "print(test_X.shape, test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 159.427\n"
     ]
    }
   ],
   "source": [
    "K.clear_session()  # Clear previous models from memory.    \n",
    "model = load_model(\"30f_future_30unit_epoch-lstm-model.h5\")\n",
    "# make a prediction\n",
    "yhat = model.predict(test_X)\n",
    "\n",
    "# invert scaling for forecast\n",
    "inv_yhat = scaler.inverse_transform(yhat)\n",
    "\n",
    "# invert scaling for actual\n",
    "inv_y = scaler.inverse_transform(test_y)\n",
    "\n",
    "# calculate RMSE\n",
    "rmse = sqrt(mean_squared_error(inv_y, inv_yhat))\n",
    "print('Test RMSE: %.3f' % rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()  # Clear previous models from memory.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(173, 30, 4)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.3368421 , 0.70094436, 0.34601355, 0.67191845],\n",
       "       [0.33631578, 0.6977964 , 0.34549242, 0.67099166],\n",
       "       [0.33631578, 0.6956978 , 0.34549242, 0.67006487],\n",
       "       [0.33578947, 0.6935991 , 0.34497133, 0.6691381 ],\n",
       "       [0.33578947, 0.6925498 , 0.34445024, 0.6691381 ],\n",
       "       [0.33526313, 0.6915005 , 0.3439291 , 0.6691381 ],\n",
       "       [0.33526313, 0.6915005 , 0.3439291 , 0.6691381 ],\n",
       "       [0.33473682, 0.6956978 , 0.34340802, 0.6691381 ],\n",
       "       [0.33473682, 0.699895  , 0.34340802, 0.67099166],\n",
       "       [0.33421052, 0.703043  , 0.3428869 , 0.67191845],\n",
       "       [0.33421052, 0.70619094, 0.3428869 , 0.67284524],\n",
       "       [0.3336842 , 0.70828956, 0.3423658 , 0.67469877],\n",
       "       [0.3336842 , 0.7093389 , 0.3418447 , 0.67562556],\n",
       "       [0.33315787, 0.7103882 , 0.34132358, 0.67840594],\n",
       "       [0.33263156, 0.7114375 , 0.3408025 , 0.68118626],\n",
       "       [0.33263156, 0.7114375 , 0.3408025 , 0.68211305],\n",
       "       [0.33263156, 0.7114375 , 0.3408025 , 0.68211305],\n",
       "       [0.33263156, 0.7114375 , 0.3408025 , 0.68211305],\n",
       "       [0.33315787, 0.7114375 , 0.34132358, 0.68211305],\n",
       "       [0.33315787, 0.7114375 , 0.3408025 , 0.68396664],\n",
       "       [0.3336842 , 0.7103882 , 0.34132358, 0.68396664],\n",
       "       [0.3336842 , 0.7103882 , 0.34132358, 0.68396664],\n",
       "       [0.3336842 , 0.7103882 , 0.34132358, 0.68396664],\n",
       "       [0.33421052, 0.7093389 , 0.3418447 , 0.68396664],\n",
       "       [0.33421052, 0.7093389 , 0.3418447 , 0.68396664],\n",
       "       [0.33421052, 0.7093389 , 0.3428869 , 0.68396664],\n",
       "       [0.33473682, 0.70828956, 0.34445024, 0.68303984],\n",
       "       [0.33473682, 0.70828956, 0.34497133, 0.68303984],\n",
       "       [0.33473682, 0.7072403 , 0.34601355, 0.68303984],\n",
       "       [0.33526313, 0.7072403 , 0.34653464, 0.68303984]], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(173, 4)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "yhat =  model.predict(np.expand_dims(test_X[0], axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "inv_yhat = scaler.inverse_transform(yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[628.5579 , 675.93713, 668.5027 , 737.423  ]], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv_yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-7e79b1c8ae02>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mdel\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdel\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "del model\n",
    "gc.collect()\n",
    "del history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.backend.tensorflow_backend import set_session\n",
    "from keras.backend.tensorflow_backend import clear_session\n",
    "from keras.backend.tensorflow_backend import get_session\n",
    "import tensorflow\n",
    "\n",
    "# Reset Keras Session\n",
    "def reset_keras():\n",
    "    sess = get_session()\n",
    "    clear_session()\n",
    "    sess.close()\n",
    "    sess = get_session()\n",
    "\n",
    "    try:\n",
    "        del classifier # this is from global space - change this as you need\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    print(gc.collect()) # if it's done something you should see a number being outputted\n",
    "\n",
    "    # use the same config as you used to create the session\n",
    "    config = tensorflow.ConfigProto()\n",
    "    config.gpu_options.per_process_gpu_memory_fraction = 1\n",
    "    config.gpu_options.visible_device_list = \"0\"\n",
    "    set_session(tensorflow.Session(config=config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'gc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-8de133b6d5dd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mreset_keras\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-12-4bb6bae41816>\u001b[0m in \u001b[0;36mreset_keras\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# if it's done something you should see a number being outputted\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;31m# use the same config as you used to create the session\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'gc' is not defined"
     ]
    }
   ],
   "source": [
    "reset_keras()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
