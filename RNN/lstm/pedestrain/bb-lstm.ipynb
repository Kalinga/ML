{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://github.com/adventuresinML/adventures-in-ml-code/blob/master/keras_lstm.py\n",
    "    \n",
    "from math import sqrt\n",
    "from numpy import concatenate\n",
    "from matplotlib import pyplot\n",
    "\n",
    "from pandas import read_csv\n",
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    "\n",
    "# for scaling and inverse_transform\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.models import load_model\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, TerminateOnNaN, CSVLogger\n",
    "\n",
    "import pickle\n",
    "\n",
    "# convert series to supervised learning\n",
    "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    print(type(data))\n",
    "\tn_vars = 1 if type(data) is list else data.shape[1]\n",
    "\tdf = DataFrame(data)\n",
    "\tcols, names = list(), list()\n",
    "\t# input sequence (t-n, ... t-1)\n",
    "\tfor i in range(n_in, 0, -1): # range([start,] stop [, step])\n",
    "        # DataFrame.shift(periods=1, freq=None, axis=0), returns DataFrame\n",
    "\t\tcols.append(df.shift(i)) \n",
    "\t\tnames += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "\t# forecast sequence (t, t+1, ... t+n)\n",
    "\tfor i in range(0, n_out):\n",
    "\t\tcols.append(df.shift(-i))\n",
    "\t\tif i == 0:\n",
    "\t\t\tnames += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "\t\telse:\n",
    "\t\t\tnames += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "\t# put it all together\n",
    "    #  concatenating along the columns (axis=1), a DataFrame is returned.\n",
    "\tagg = concat(cols, axis=1)\n",
    "\tagg.columns = names\n",
    "\t# drop rows with NaN values\n",
    "\tif dropnan:\n",
    "\t\tagg.dropna(inplace=True)\n",
    "\treturn agg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7980093676814989"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bb_intersection_over_union([39, 63, 203, 112], [54, 66, 198, 114])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(84371, 4)\n",
      "[1900.  953. 1919. 1079.]\n",
      "[0. 0. 0. 0.]\n",
      "(84341, 124)\n",
      "(64372, 120) 64372 (64372, 4)\n",
      "(64372, 30, 4) (64372, 4) (19969, 30, 4) (19969, 4)\n"
     ]
    }
   ],
   "source": [
    "# load dataset\n",
    "dataset = read_csv('bb-cross-train.csv', header=0)\n",
    "values = dataset.values\n",
    "print(values.shape)\n",
    "\n",
    "# ensure all data is float\n",
    "values = values.astype('float32')\n",
    "\n",
    "# normalize features\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled = scaler.fit_transform(values)\n",
    "print(scaler.data_max_)\n",
    "print(scaler.data_min_)\n",
    "\n",
    "pickle.dump(scaler, open(\"min-max-scaler.pkl\", 'wb'))\n",
    "\n",
    "# specify the number of lag hours\n",
    "n_seq = 30\n",
    "n_features = 4\n",
    "# frame as supervised learning\n",
    "reframed = series_to_supervised(scaled, n_seq, 1)\n",
    "print(reframed.shape)\n",
    "\n",
    "# split into train and test sets\n",
    "values = reframed.values\n",
    "n_train_num = 84372 - 20000\n",
    "train = values[:n_train_num, :]\n",
    "val = values[n_train_num:, :]\n",
    "\n",
    "# split into input and outputs\n",
    "n_obs = n_seq * n_features\n",
    "train_X, train_y = train[:, :n_obs], train[:, n_obs:n_obs+n_features]\n",
    "val_X, val_y = val[:, :n_obs], val[:, n_obs:n_obs+n_features]\n",
    "print(train_X.shape, len(train_X), train_y.shape)\n",
    "\n",
    "# reshape input to be 3D [samples, timesteps, features]\n",
    "train_X = train_X.reshape((train_X.shape[0], n_seq, n_features))\n",
    "val_X = val_X.reshape((val_X.shape[0], n_seq, n_features))\n",
    "print(train_X.shape, train_y.shape, val_X.shape, val_y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.40842104, 0.71773344, 0.41010943, 0.6645042 ], dtype=float32)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64372, 30, 4)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19969, 30, 4)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model callbacks.\n",
    "\n",
    "# TODO: Set the filepath under which you want to save the weights.\n",
    "model_checkpoint = ModelCheckpoint(filepath='conf3_bb_lstm_epoch-{epoch:02d}_loss-{loss:.4f}_val_loss-{val_loss:.4f}.h5',\n",
    "                                   monitor='val_loss',\n",
    "                                   verbose=1,\n",
    "                                   save_best_only=True,\n",
    "                                   save_weights_only=False,\n",
    "                                   mode='auto',\n",
    "                                   period=1)\n",
    "\n",
    "csv_logger = CSVLogger(filename='bb_lstm_training_log.csv',\n",
    "                       separator=',',\n",
    "                       append=True)\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss',\n",
    "                               min_delta=0.0,\n",
    "                               patience=10,\n",
    "                               verbose=1)\n",
    "\n",
    "#reduce_learning_rate = ReduceLROnPlateau(monitor='val_loss',\n",
    "#                                         factor=0.2,\n",
    "#                                         patience=8,\n",
    "#                                         verbose=1,\n",
    "#                                         epsilon=0.001,\n",
    "#                                         cooldown=0,\n",
    "#                                         min_lr=0.00001)\n",
    "\n",
    "callbacks = [model_checkpoint,\n",
    "             csv_logger,\n",
    "             early_stopping\n",
    "             #reduce_learning_rate]\n",
    "            ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 64372 samples, validate on 19969 samples\n",
      "Epoch 1/200\n",
      " - 47s - loss: 0.0470 - val_loss: 0.0340\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.03396, saving model to conf3_bb_lstm_epoch-01_loss-0.0470_val_loss-0.0340.h5\n",
      "Epoch 2/200\n",
      " - 47s - loss: 0.0249 - val_loss: 0.0278\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.03396 to 0.02777, saving model to conf3_bb_lstm_epoch-02_loss-0.0249_val_loss-0.0278.h5\n",
      "Epoch 3/200\n",
      " - 47s - loss: 0.0214 - val_loss: 0.0269\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.02777 to 0.02687, saving model to conf3_bb_lstm_epoch-03_loss-0.0214_val_loss-0.0269.h5\n",
      "Epoch 4/200\n",
      " - 47s - loss: 0.0194 - val_loss: 0.0237\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.02687 to 0.02365, saving model to conf3_bb_lstm_epoch-04_loss-0.0194_val_loss-0.0237.h5\n",
      "Epoch 5/200\n",
      " - 47s - loss: 0.0175 - val_loss: 0.0202\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.02365 to 0.02023, saving model to conf3_bb_lstm_epoch-05_loss-0.0175_val_loss-0.0202.h5\n",
      "Epoch 6/200\n",
      " - 48s - loss: 0.0166 - val_loss: 0.0220\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.02023\n",
      "Epoch 7/200\n",
      " - 47s - loss: 0.0161 - val_loss: 0.0152\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.02023 to 0.01518, saving model to conf3_bb_lstm_epoch-07_loss-0.0161_val_loss-0.0152.h5\n",
      "Epoch 8/200\n",
      " - 48s - loss: 0.0146 - val_loss: 0.0155\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.01518\n",
      "Epoch 9/200\n",
      " - 48s - loss: 0.0144 - val_loss: 0.0176\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.01518\n",
      "Epoch 10/200\n",
      " - 48s - loss: 0.0130 - val_loss: 0.0179\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.01518\n",
      "Epoch 11/200\n",
      " - 48s - loss: 0.0119 - val_loss: 0.0151\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.01518 to 0.01514, saving model to conf3_bb_lstm_epoch-11_loss-0.0119_val_loss-0.0151.h5\n",
      "Epoch 12/200\n",
      " - 48s - loss: 0.0122 - val_loss: 0.0181\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.01514\n",
      "Epoch 13/200\n",
      " - 48s - loss: 0.0118 - val_loss: 0.0159\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.01514\n",
      "Epoch 14/200\n",
      " - 48s - loss: 0.0110 - val_loss: 0.0140\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.01514 to 0.01405, saving model to conf3_bb_lstm_epoch-14_loss-0.0110_val_loss-0.0140.h5\n",
      "Epoch 15/200\n",
      " - 48s - loss: 0.0106 - val_loss: 0.0170\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.01405\n",
      "Epoch 16/200\n",
      " - 47s - loss: 0.0106 - val_loss: 0.0120\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.01405 to 0.01205, saving model to conf3_bb_lstm_epoch-16_loss-0.0106_val_loss-0.0120.h5\n",
      "Epoch 17/200\n",
      " - 47s - loss: 0.0107 - val_loss: 0.0117\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.01205 to 0.01172, saving model to conf3_bb_lstm_epoch-17_loss-0.0107_val_loss-0.0117.h5\n",
      "Epoch 18/200\n",
      " - 47s - loss: 0.0101 - val_loss: 0.0117\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.01172 to 0.01169, saving model to conf3_bb_lstm_epoch-18_loss-0.0101_val_loss-0.0117.h5\n",
      "Epoch 19/200\n",
      " - 47s - loss: 0.0102 - val_loss: 0.0096\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.01169 to 0.00963, saving model to conf3_bb_lstm_epoch-19_loss-0.0102_val_loss-0.0096.h5\n",
      "Epoch 20/200\n",
      " - 47s - loss: 0.0094 - val_loss: 0.0107\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.00963\n",
      "Epoch 21/200\n",
      " - 47s - loss: 0.0089 - val_loss: 0.0130\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.00963\n",
      "Epoch 22/200\n",
      " - 47s - loss: 0.0093 - val_loss: 0.0106\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.00963\n",
      "Epoch 23/200\n",
      " - 47s - loss: 0.0088 - val_loss: 0.0095\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.00963 to 0.00952, saving model to conf3_bb_lstm_epoch-23_loss-0.0088_val_loss-0.0095.h5\n",
      "Epoch 24/200\n",
      " - 47s - loss: 0.0087 - val_loss: 0.0110\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.00952\n",
      "Epoch 25/200\n",
      " - 47s - loss: 0.0087 - val_loss: 0.0083\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.00952 to 0.00833, saving model to conf3_bb_lstm_epoch-25_loss-0.0087_val_loss-0.0083.h5\n",
      "Epoch 26/200\n",
      " - 48s - loss: 0.0087 - val_loss: 0.0097\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.00833\n",
      "Epoch 27/200\n",
      " - 48s - loss: 0.0082 - val_loss: 0.0097\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.00833\n",
      "Epoch 28/200\n",
      " - 47s - loss: 0.0081 - val_loss: 0.0095\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.00833\n",
      "Epoch 29/200\n",
      " - 47s - loss: 0.0082 - val_loss: 0.0132\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.00833\n",
      "Epoch 30/200\n",
      " - 47s - loss: 0.0082 - val_loss: 0.0098\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.00833\n",
      "Epoch 31/200\n",
      " - 48s - loss: 0.0080 - val_loss: 0.0105\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.00833\n",
      "Epoch 32/200\n",
      " - 47s - loss: 0.0079 - val_loss: 0.0090\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.00833\n",
      "Epoch 33/200\n",
      " - 48s - loss: 0.0081 - val_loss: 0.0101\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.00833\n",
      "Epoch 34/200\n",
      " - 47s - loss: 0.0076 - val_loss: 0.0087\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.00833\n",
      "Epoch 35/200\n",
      " - 47s - loss: 0.0076 - val_loss: 0.0083\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.00833 to 0.00827, saving model to conf3_bb_lstm_epoch-35_loss-0.0076_val_loss-0.0083.h5\n",
      "Epoch 36/200\n",
      " - 47s - loss: 0.0077 - val_loss: 0.0099\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.00827\n",
      "Epoch 37/200\n",
      " - 47s - loss: 0.0075 - val_loss: 0.0103\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.00827\n",
      "Epoch 38/200\n",
      " - 48s - loss: 0.0079 - val_loss: 0.0090\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.00827\n",
      "Epoch 39/200\n",
      " - 47s - loss: 0.0074 - val_loss: 0.0095\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.00827\n",
      "Epoch 40/200\n",
      " - 48s - loss: 0.0077 - val_loss: 0.0098\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.00827\n",
      "Epoch 41/200\n",
      " - 47s - loss: 0.0075 - val_loss: 0.0093\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.00827\n",
      "Epoch 42/200\n",
      " - 48s - loss: 0.0075 - val_loss: 0.0094\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.00827\n",
      "Epoch 43/200\n",
      " - 48s - loss: 0.0076 - val_loss: 0.0081\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.00827 to 0.00810, saving model to conf3_bb_lstm_epoch-43_loss-0.0076_val_loss-0.0081.h5\n",
      "Epoch 44/200\n",
      " - 47s - loss: 0.0069 - val_loss: 0.0089\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.00810\n",
      "Epoch 45/200\n",
      " - 47s - loss: 0.0069 - val_loss: 0.0086\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.00810\n",
      "Epoch 46/200\n",
      " - 47s - loss: 0.0070 - val_loss: 0.0102\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.00810\n",
      "Epoch 47/200\n",
      " - 47s - loss: 0.0073 - val_loss: 0.0083\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.00810\n",
      "Epoch 48/200\n",
      " - 48s - loss: 0.0070 - val_loss: 0.0093\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.00810\n",
      "Epoch 49/200\n",
      " - 47s - loss: 0.0074 - val_loss: 0.0090\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.00810\n",
      "Epoch 50/200\n",
      " - 47s - loss: 0.0071 - val_loss: 0.0080\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.00810 to 0.00804, saving model to conf3_bb_lstm_epoch-50_loss-0.0071_val_loss-0.0080.h5\n",
      "Epoch 51/200\n",
      " - 47s - loss: 0.0071 - val_loss: 0.0091\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.00804\n",
      "Epoch 52/200\n",
      " - 48s - loss: 0.0069 - val_loss: 0.0083\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.00804\n",
      "Epoch 53/200\n",
      " - 47s - loss: 0.0072 - val_loss: 0.0081\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.00804\n",
      "Epoch 54/200\n",
      " - 47s - loss: 0.0074 - val_loss: 0.0083\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.00804\n",
      "Epoch 55/200\n",
      " - 47s - loss: 0.0069 - val_loss: 0.0091\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.00804\n",
      "Epoch 56/200\n",
      " - 47s - loss: 0.0070 - val_loss: 0.0089\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.00804\n",
      "Epoch 57/200\n",
      " - 47s - loss: 0.0070 - val_loss: 0.0083\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.00804\n",
      "Epoch 58/200\n",
      " - 48s - loss: 0.0070 - val_loss: 0.0089\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.00804\n",
      "Epoch 59/200\n",
      " - 48s - loss: 0.0070 - val_loss: 0.0079\n",
      "\n",
      "Epoch 00059: val_loss improved from 0.00804 to 0.00792, saving model to conf3_bb_lstm_epoch-59_loss-0.0070_val_loss-0.0079.h5\n",
      "Epoch 60/200\n",
      " - 48s - loss: 0.0068 - val_loss: 0.0091\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.00792\n",
      "Epoch 61/200\n",
      " - 48s - loss: 0.0071 - val_loss: 0.0080\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.00792\n",
      "Epoch 62/200\n",
      " - 47s - loss: 0.0065 - val_loss: 0.0081\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.00792\n",
      "Epoch 63/200\n",
      " - 48s - loss: 0.0067 - val_loss: 0.0093\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.00792\n",
      "Epoch 64/200\n",
      " - 48s - loss: 0.0068 - val_loss: 0.0103\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.00792\n",
      "Epoch 65/200\n",
      " - 48s - loss: 0.0070 - val_loss: 0.0081\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00065: val_loss did not improve from 0.00792\n",
      "Epoch 66/200\n",
      " - 48s - loss: 0.0068 - val_loss: 0.0094\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.00792\n",
      "Epoch 67/200\n",
      " - 48s - loss: 0.0066 - val_loss: 0.0075\n",
      "\n",
      "Epoch 00067: val_loss improved from 0.00792 to 0.00746, saving model to conf3_bb_lstm_epoch-67_loss-0.0066_val_loss-0.0075.h5\n",
      "Epoch 68/200\n",
      " - 48s - loss: 0.0067 - val_loss: 0.0081\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.00746\n",
      "Epoch 69/200\n",
      " - 48s - loss: 0.0067 - val_loss: 0.0077\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.00746\n",
      "Epoch 70/200\n",
      " - 48s - loss: 0.0066 - val_loss: 0.0105\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.00746\n",
      "Epoch 71/200\n",
      " - 48s - loss: 0.0065 - val_loss: 0.0087\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.00746\n",
      "Epoch 72/200\n",
      " - 48s - loss: 0.0065 - val_loss: 0.0085\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.00746\n",
      "Epoch 73/200\n",
      " - 47s - loss: 0.0068 - val_loss: 0.0086\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.00746\n",
      "Epoch 74/200\n",
      " - 47s - loss: 0.0065 - val_loss: 0.0073\n",
      "\n",
      "Epoch 00074: val_loss improved from 0.00746 to 0.00732, saving model to conf3_bb_lstm_epoch-74_loss-0.0065_val_loss-0.0073.h5\n",
      "Epoch 75/200\n",
      " - 47s - loss: 0.0064 - val_loss: 0.0092\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.00732\n",
      "Epoch 76/200\n",
      " - 48s - loss: 0.0064 - val_loss: 0.0099\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.00732\n",
      "Epoch 77/200\n",
      " - 47s - loss: 0.0064 - val_loss: 0.0073\n",
      "\n",
      "Epoch 00077: val_loss improved from 0.00732 to 0.00731, saving model to conf3_bb_lstm_epoch-77_loss-0.0064_val_loss-0.0073.h5\n",
      "Epoch 78/200\n",
      " - 47s - loss: 0.0062 - val_loss: 0.0070\n",
      "\n",
      "Epoch 00078: val_loss improved from 0.00731 to 0.00696, saving model to conf3_bb_lstm_epoch-78_loss-0.0062_val_loss-0.0070.h5\n",
      "Epoch 79/200\n",
      " - 46s - loss: 0.0064 - val_loss: 0.0086\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.00696\n",
      "Epoch 80/200\n",
      " - 47s - loss: 0.0064 - val_loss: 0.0081\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.00696\n",
      "Epoch 81/200\n",
      " - 47s - loss: 0.0064 - val_loss: 0.0082\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.00696\n",
      "Epoch 82/200\n",
      " - 47s - loss: 0.0063 - val_loss: 0.0076\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.00696\n",
      "Epoch 83/200\n",
      " - 48s - loss: 0.0061 - val_loss: 0.0084\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.00696\n",
      "Epoch 84/200\n",
      " - 47s - loss: 0.0064 - val_loss: 0.0079\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.00696\n",
      "Epoch 85/200\n",
      " - 47s - loss: 0.0063 - val_loss: 0.0070\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.00696\n",
      "Epoch 86/200\n",
      " - 47s - loss: 0.0063 - val_loss: 0.0087\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.00696\n",
      "Epoch 87/200\n",
      " - 47s - loss: 0.0066 - val_loss: 0.0081\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.00696\n",
      "Epoch 88/200\n",
      " - 47s - loss: 0.0063 - val_loss: 0.0075\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.00696\n",
      "Epoch 00088: early stopping\n"
     ]
    }
   ],
   "source": [
    " # design network\n",
    "K.clear_session()  # Clear previous models from memory.    \n",
    "model = Sequential()\n",
    "model.add(LSTM(50, input_shape=(train_X.shape[1], train_X.shape[2])))\n",
    "model.add(Dense(4))\n",
    "model.compile(loss='mae', optimizer='adam')\n",
    "\n",
    "epochs = 200\n",
    "# fit network\n",
    "history = model.fit(train_X, train_y, \n",
    "                    epochs=epochs, \n",
    "                    batch_size=72, \n",
    "                    validation_data=(val_X, val_y), \n",
    "                    verbose=2,\n",
    "                    callbacks=callbacks,\n",
    "                    shuffle=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot history\n",
    "pyplot.plot(history.history['loss'], label='train')\n",
    "pyplot.plot(history.history['val_loss'], label='test')\n",
    "pyplot.legend()\n",
    "pyplot.savefig(\"conf3-lstm-model.png\")\n",
    "pyplot.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model\n",
    "model.save(\"conf3-lstm-model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "204\n",
      "[1900.  953. 1919. 1079.]\n",
      "[0. 0. 0. 0.]\n",
      "(174, 124)\n",
      "(174, 120) 174 (174, 4)\n",
      "(174, 30, 4) (174, 4)\n"
     ]
    }
   ],
   "source": [
    "# load test dataset\n",
    "values = read_csv('bb-cross-test1.csv', header=0).values\n",
    "print(len(values))\n",
    "# ensure all data is float\n",
    "values = values.astype('float32')\n",
    "\n",
    "# normalize features\n",
    "\n",
    "scaled = scaler.transform(values)\n",
    "print(scaler.data_max_)\n",
    "print(scaler.data_min_)\n",
    "\n",
    "# specify the number of lag hours\n",
    "#n_seq = 15\n",
    "#n_features = 4\n",
    "\n",
    "# frame as supervised learning\n",
    "reframed = series_to_supervised(scaled, n_seq, 1)\n",
    "print(reframed.shape)\n",
    "values = reframed.values\n",
    "\n",
    "# split into input and outputs\n",
    "n_obs = n_seq * n_features\n",
    "test_X, test_y = values[:, :n_obs], values[:, n_obs:n_obs+n_features]\n",
    "print(test_X.shape, len(test_X), test_y.shape)\n",
    "\n",
    "# reshape input to be 3D [samples, timesteps, features]\n",
    "test_X = test_X.reshape((test_X.shape[0], n_seq, n_features))\n",
    "print(test_X.shape, test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 4.625\n"
     ]
    }
   ],
   "source": [
    "K.clear_session()  # Clear previous models from memory.    \n",
    "model = load_model(\"conf3-lstm-model.h5\")\n",
    "# make a prediction\n",
    "yhat = model.predict(test_X)\n",
    "\n",
    "# invert scaling for forecast\n",
    "inv_yhat = scaler.inverse_transform(yhat)\n",
    "\n",
    "# invert scaling for actual\n",
    "inv_y = scaler.inverse_transform(test_y)\n",
    "\n",
    "# calculate RMSE\n",
    "rmse = sqrt(mean_squared_error(inv_y, inv_yhat))\n",
    "print('Test RMSE: %.3f' % rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(189, 15, 4)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.3368421 , 0.70094436, 0.34601355, 0.67191845],\n",
       "       [0.33631578, 0.6977964 , 0.34549242, 0.67099166],\n",
       "       [0.33631578, 0.6956978 , 0.34549242, 0.67006487],\n",
       "       [0.33578947, 0.6935991 , 0.34497133, 0.6691381 ],\n",
       "       [0.33578947, 0.6925498 , 0.34445024, 0.6691381 ],\n",
       "       [0.33526313, 0.6915005 , 0.3439291 , 0.6691381 ],\n",
       "       [0.33526313, 0.6915005 , 0.3439291 , 0.6691381 ],\n",
       "       [0.33473682, 0.6956978 , 0.34340802, 0.6691381 ],\n",
       "       [0.33473682, 0.699895  , 0.34340802, 0.67099166],\n",
       "       [0.33421052, 0.703043  , 0.3428869 , 0.67191845],\n",
       "       [0.33421052, 0.70619094, 0.3428869 , 0.67284524],\n",
       "       [0.3336842 , 0.70828956, 0.3423658 , 0.67469877],\n",
       "       [0.3336842 , 0.7093389 , 0.3418447 , 0.67562556],\n",
       "       [0.33315787, 0.7103882 , 0.34132358, 0.67840594],\n",
       "       [0.33263156, 0.7114375 , 0.3408025 , 0.68118626]], dtype=float32)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(189, 4)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "yhat =  model.predict(np.expand_dims(test_X[0], axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "inv_yhat = scaler.inverse_transform(yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1122.4075,  692.9786, 1214.8446,  859.0956]], dtype=float32)"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv_yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
