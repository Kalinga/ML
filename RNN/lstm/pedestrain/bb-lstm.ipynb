{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://github.com/adventuresinML/adventures-in-ml-code/blob/master/keras_lstm.py\n",
    "    \n",
    "from math import sqrt\n",
    "from numpy import concatenate\n",
    "from matplotlib import pyplot\n",
    "\n",
    "from pandas import read_csv\n",
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    "\n",
    "# for scaling and inverse_transform\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.models import load_model\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, TerminateOnNaN, CSVLogger\n",
    "\n",
    "import pickle\n",
    "\n",
    "# convert series to supervised learning\n",
    "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "\tn_vars = 1 if type(data) is list else data.shape[1]\n",
    "\tdf = DataFrame(data)\n",
    "\tcols, names = list(), list()\n",
    "\t# input sequence (t-n, ... t-1)\n",
    "\tfor i in range(n_in, 0, -1): # range([start,] stop [, step])\n",
    "        # DataFrame.shift(periods=1, freq=None, axis=0), returns DataFrame\n",
    "\t\tcols.append(df.shift(i)) \n",
    "\t\tnames += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "\t# forecast sequence (t, t+1, ... t+n)\n",
    "\tfor i in range(0, n_out):\n",
    "\t\tcols.append(df.shift(-i))\n",
    "\t\tif i == 0:\n",
    "\t\t\tnames += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "\t\telse:\n",
    "\t\t\tnames += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "\t# put it all together\n",
    "    #  concatenating along the columns (axis=1), a DataFrame is returned.\n",
    "\tagg = concat(cols, axis=1)\n",
    "\tagg.columns = names\n",
    "\t# drop rows with NaN values\n",
    "\tif dropnan:\n",
    "\t\tagg.dropna(inplace=True)\n",
    "\treturn agg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(84371, 4)\n",
      "[1900.  953. 1919. 1079.]\n",
      "[0. 0. 0. 0.]\n",
      "(84356, 64)\n",
      "(64372, 60) 64372 (64372, 4)\n",
      "(64372, 15, 4) (64372, 4) (19984, 15, 4) (19984, 4)\n"
     ]
    }
   ],
   "source": [
    "# load dataset\n",
    "dataset = read_csv('bb-cross-train.csv', header=0)\n",
    "values = dataset.values\n",
    "print(values.shape)\n",
    "\n",
    "# ensure all data is float\n",
    "values = values.astype('float32')\n",
    "\n",
    "# normalize features\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled = scaler.fit_transform(values)\n",
    "print(scaler.data_max_)\n",
    "print(scaler.data_min_)\n",
    "\n",
    "pickle.dump(scaler, open(\"min-max-scaler.pkl\", 'wb'))\n",
    "\n",
    "# specify the number of lag hours\n",
    "n_seq = 15\n",
    "n_features = 4\n",
    "# frame as supervised learning\n",
    "reframed = series_to_supervised(scaled, n_seq, 1)\n",
    "print(reframed.shape)\n",
    "\n",
    "# split into train and test sets\n",
    "values = reframed.values\n",
    "n_train_num = 84372 - 20000\n",
    "train = values[:n_train_num, :]\n",
    "val = values[n_train_num:, :]\n",
    "\n",
    "# split into input and outputs\n",
    "n_obs = n_seq * n_features\n",
    "train_X, train_y = train[:, :n_obs], train[:, n_obs:n_obs+n_features]\n",
    "val_X, val_y = val[:, :n_obs], val[:, n_obs:n_obs+n_features]\n",
    "print(train_X.shape, len(train_X), train_y.shape)\n",
    "\n",
    "# reshape input to be 3D [samples, timesteps, features]\n",
    "train_X = train_X.reshape((train_X.shape[0], n_seq, n_features))\n",
    "val_X = val_X.reshape((val_X.shape[0], n_seq, n_features))\n",
    "print(train_X.shape, train_y.shape, val_X.shape, val_y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.40842104, 0.71773344, 0.41010943, 0.6645042 ], dtype=float32)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X.shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19984, 15, 4)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model callbacks.\n",
    "\n",
    "# TODO: Set the filepath under which you want to save the weights.\n",
    "model_checkpoint = ModelCheckpoint(filepath='conf2_bb_lstm_epoch-{epoch:02d}_loss-{loss:.4f}_val_loss-{val_loss:.4f}.h5',\n",
    "                                   monitor='val_loss',\n",
    "                                   verbose=1,\n",
    "                                   save_best_only=True,\n",
    "                                   save_weights_only=False,\n",
    "                                   mode='auto',\n",
    "                                   period=1)\n",
    "\n",
    "csv_logger = CSVLogger(filename='bb_lstm_training_log.csv',\n",
    "                       separator=',',\n",
    "                       append=True)\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss',\n",
    "                               min_delta=0.0,\n",
    "                               patience=10,\n",
    "                               verbose=1)\n",
    "\n",
    "#reduce_learning_rate = ReduceLROnPlateau(monitor='val_loss',\n",
    "#                                         factor=0.2,\n",
    "#                                         patience=8,\n",
    "#                                         verbose=1,\n",
    "#                                         epsilon=0.001,\n",
    "#                                         cooldown=0,\n",
    "#                                         min_lr=0.00001)\n",
    "\n",
    "callbacks = [model_checkpoint,\n",
    "             csv_logger,\n",
    "             early_stopping\n",
    "             #reduce_learning_rate]\n",
    "            ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 64372 samples, validate on 19984 samples\n",
      "Epoch 1/200\n",
      " - 28s - loss: 0.0512 - val_loss: 0.0267\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.02668, saving model to conf2_bb_lstm_epoch-01_loss-0.0512_val_loss-0.0267.h5\n",
      "Epoch 2/200\n",
      " - 27s - loss: 0.0235 - val_loss: 0.0268\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.02668\n",
      "Epoch 3/200\n",
      " - 27s - loss: 0.0207 - val_loss: 0.0221\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.02668 to 0.02211, saving model to conf2_bb_lstm_epoch-03_loss-0.0207_val_loss-0.0221.h5\n",
      "Epoch 4/200\n",
      " - 27s - loss: 0.0180 - val_loss: 0.0227\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.02211\n",
      "Epoch 5/200\n",
      " - 27s - loss: 0.0165 - val_loss: 0.0174\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.02211 to 0.01744, saving model to conf2_bb_lstm_epoch-05_loss-0.0165_val_loss-0.0174.h5\n",
      "Epoch 6/200\n",
      " - 27s - loss: 0.0159 - val_loss: 0.0155\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.01744 to 0.01548, saving model to conf2_bb_lstm_epoch-06_loss-0.0159_val_loss-0.0155.h5\n",
      "Epoch 7/200\n",
      " - 27s - loss: 0.0157 - val_loss: 0.0159\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.01548\n",
      "Epoch 8/200\n",
      " - 27s - loss: 0.0135 - val_loss: 0.0150\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.01548 to 0.01499, saving model to conf2_bb_lstm_epoch-08_loss-0.0135_val_loss-0.0150.h5\n",
      "Epoch 9/200\n",
      " - 27s - loss: 0.0129 - val_loss: 0.0137\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.01499 to 0.01371, saving model to conf2_bb_lstm_epoch-09_loss-0.0129_val_loss-0.0137.h5\n",
      "Epoch 10/200\n",
      " - 27s - loss: 0.0124 - val_loss: 0.0166\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.01371\n",
      "Epoch 11/200\n",
      " - 27s - loss: 0.0119 - val_loss: 0.0159\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.01371\n",
      "Epoch 12/200\n",
      " - 27s - loss: 0.0121 - val_loss: 0.0142\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.01371\n",
      "Epoch 13/200\n",
      " - 27s - loss: 0.0119 - val_loss: 0.0198\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.01371\n",
      "Epoch 14/200\n",
      " - 27s - loss: 0.0121 - val_loss: 0.0173\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.01371\n",
      "Epoch 15/200\n",
      " - 27s - loss: 0.0118 - val_loss: 0.0163\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.01371\n",
      "Epoch 16/200\n",
      " - 27s - loss: 0.0116 - val_loss: 0.0134\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.01371 to 0.01337, saving model to conf2_bb_lstm_epoch-16_loss-0.0116_val_loss-0.0134.h5\n",
      "Epoch 17/200\n",
      " - 27s - loss: 0.0106 - val_loss: 0.0141\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.01337\n",
      "Epoch 18/200\n",
      " - 27s - loss: 0.0104 - val_loss: 0.0123\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.01337 to 0.01231, saving model to conf2_bb_lstm_epoch-18_loss-0.0104_val_loss-0.0123.h5\n",
      "Epoch 19/200\n",
      " - 27s - loss: 0.0103 - val_loss: 0.0105\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.01231 to 0.01050, saving model to conf2_bb_lstm_epoch-19_loss-0.0103_val_loss-0.0105.h5\n",
      "Epoch 20/200\n",
      " - 27s - loss: 0.0096 - val_loss: 0.0126\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.01050\n",
      "Epoch 21/200\n",
      " - 27s - loss: 0.0092 - val_loss: 0.0114\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.01050\n",
      "Epoch 22/200\n",
      " - 27s - loss: 0.0092 - val_loss: 0.0103\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.01050 to 0.01034, saving model to conf2_bb_lstm_epoch-22_loss-0.0092_val_loss-0.0103.h5\n",
      "Epoch 23/200\n",
      " - 27s - loss: 0.0087 - val_loss: 0.0089\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.01034 to 0.00888, saving model to conf2_bb_lstm_epoch-23_loss-0.0087_val_loss-0.0089.h5\n",
      "Epoch 24/200\n",
      " - 27s - loss: 0.0086 - val_loss: 0.0113\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.00888\n",
      "Epoch 25/200\n",
      " - 27s - loss: 0.0091 - val_loss: 0.0113\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.00888\n",
      "Epoch 26/200\n",
      " - 27s - loss: 0.0087 - val_loss: 0.0105\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.00888\n",
      "Epoch 27/200\n",
      " - 27s - loss: 0.0083 - val_loss: 0.0133\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.00888\n",
      "Epoch 28/200\n",
      " - 27s - loss: 0.0083 - val_loss: 0.0109\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.00888\n",
      "Epoch 29/200\n",
      " - 27s - loss: 0.0080 - val_loss: 0.0112\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.00888\n",
      "Epoch 30/200\n",
      " - 27s - loss: 0.0078 - val_loss: 0.0108\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.00888\n",
      "Epoch 31/200\n",
      " - 27s - loss: 0.0080 - val_loss: 0.0113\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.00888\n",
      "Epoch 32/200\n",
      " - 27s - loss: 0.0080 - val_loss: 0.0095\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.00888\n",
      "Epoch 33/200\n",
      " - 27s - loss: 0.0083 - val_loss: 0.0091\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.00888\n",
      "Epoch 00033: early stopping\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    " # design network\n",
    "K.clear_session()  # Clear previous models from memory.    \n",
    "model = Sequential()\n",
    "model.add(LSTM(50, input_shape=(train_X.shape[1], train_X.shape[2])))\n",
    "model.add(Dense(4))\n",
    "model.compile(loss='mae', optimizer='adam')\n",
    "\n",
    "epochs = 200\n",
    "# fit network\n",
    "history = model.fit(train_X, train_y, \n",
    "                    epochs=epochs, \n",
    "                    batch_size=72, \n",
    "                    validation_data=(val_X, val_y), \n",
    "                    verbose=2,\n",
    "                    callbacks=callbacks,\n",
    "                    shuffle=False)\n",
    "\n",
    "# plot history\n",
    "pyplot.plot(history.history['loss'], label='train')\n",
    "pyplot.plot(history.history['val_loss'], label='test')\n",
    "pyplot.legend()\n",
    "pyplot.savefig(\"conf2-lstm-model.png\")\n",
    "pyplot.show()\n",
    "\n",
    "\n",
    "# save the model\n",
    "model.save(\"conf2-lstm-model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model\n",
    "model.save(\"conf2-lstm-model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "204\n",
      "[1900.  953. 1919. 1079.]\n",
      "[0. 0. 0. 0.]\n",
      "(189, 64)\n",
      "(189, 60) 189 (189, 4)\n",
      "(189, 15, 4) (189, 4)\n"
     ]
    }
   ],
   "source": [
    "# load test dataset\n",
    "values = read_csv('bb-cross-test1.csv', header=0).values\n",
    "print(len(values))\n",
    "# ensure all data is float\n",
    "values = values.astype('float32')\n",
    "\n",
    "# normalize features\n",
    "\n",
    "scaled = scaler.transform(values)\n",
    "print(scaler.data_max_)\n",
    "print(scaler.data_min_)\n",
    "\n",
    "# specify the number of lag hours\n",
    "n_seq = 15\n",
    "n_features = 4\n",
    "# frame as supervised learning\n",
    "reframed = series_to_supervised(scaled, n_seq, 1)\n",
    "print(reframed.shape)\n",
    "values = reframed.values\n",
    "\n",
    "# split into input and outputs\n",
    "n_obs = n_seq * n_features\n",
    "test_X, test_y = values[:, :n_obs], values[:, n_obs:n_obs+n_features]\n",
    "print(test_X.shape, len(test_X), test_y.shape)\n",
    "\n",
    "# reshape input to be 3D [samples, timesteps, features]\n",
    "test_X = test_X.reshape((test_X.shape[0], n_seq, n_features))\n",
    "print(test_X.shape, test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 4.749\n"
     ]
    }
   ],
   "source": [
    "K.clear_session()  # Clear previous models from memory.    \n",
    "model = load_model(\"conf2-lstm-model.h5\")\n",
    "# make a prediction\n",
    "yhat = model.predict(test_X)\n",
    "\n",
    "# invert scaling for forecast\n",
    "inv_yhat = scaler.inverse_transform(yhat)\n",
    "\n",
    "# invert scaling for actual\n",
    "inv_y = scaler.inverse_transform(test_y)\n",
    "\n",
    "# calculate RMSE\n",
    "rmse = sqrt(mean_squared_error(inv_y, inv_yhat))\n",
    "print('Test RMSE: %.3f' % rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(189, 15, 4)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.3368421 , 0.70094436, 0.34601355, 0.67191845],\n",
       "       [0.33631578, 0.6977964 , 0.34549242, 0.67099166],\n",
       "       [0.33631578, 0.6956978 , 0.34549242, 0.67006487],\n",
       "       [0.33578947, 0.6935991 , 0.34497133, 0.6691381 ],\n",
       "       [0.33578947, 0.6925498 , 0.34445024, 0.6691381 ],\n",
       "       [0.33526313, 0.6915005 , 0.3439291 , 0.6691381 ],\n",
       "       [0.33526313, 0.6915005 , 0.3439291 , 0.6691381 ],\n",
       "       [0.33473682, 0.6956978 , 0.34340802, 0.6691381 ],\n",
       "       [0.33473682, 0.699895  , 0.34340802, 0.67099166],\n",
       "       [0.33421052, 0.703043  , 0.3428869 , 0.67191845],\n",
       "       [0.33421052, 0.70619094, 0.3428869 , 0.67284524],\n",
       "       [0.3336842 , 0.70828956, 0.3423658 , 0.67469877],\n",
       "       [0.3336842 , 0.7093389 , 0.3418447 , 0.67562556],\n",
       "       [0.33315787, 0.7103882 , 0.34132358, 0.67840594],\n",
       "       [0.33263156, 0.7114375 , 0.3408025 , 0.68118626]], dtype=float32)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(189, 4)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "yhat =  model.predict(np.expand_dims(test_X[0], axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "inv_yhat = scaler.inverse_transform(yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1122.4075,  692.9786, 1214.8446,  859.0956]], dtype=float32)"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv_yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
